# EnCarbonSys Robots.txt - SEO Optimized
# Updated: February 23, 2026

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Sitemap locations (Primary)
Sitemap: https://encarbonsys.com/sitemap.xml
Sitemap: https://encarbonsys.com/sitemap-blog.xml

# Crawl-delay for polite crawling
Crawl-delay: 1

# Disallow internal/template files (not for indexing)
Disallow: /docs/
Disallow: /scripts/
Disallow: /components/meta-tags-template.html
Disallow: /components/blog-widget.html
Disallow: /cbam-blog/temp-references-section.html
Disallow: /*.md$
Disallow: /*.py$

# Allow important pages (explicit)
Allow: /
Allow: /pages/encbam-pro.html
Allow: /pages/pricing.html
Allow: /pages/client-resource.html
Allow: /cbam-blog/

# Allow CSS, JS, images for rendering
Allow: /assets/css/
Allow: /assets/js/
Allow: /assets/images/
Allow: /assets/pdf/brochure.pdf

# Specific bot instructions
User-agent: Googlebot
Allow: /
Crawl-delay: 1

User-agent: Googlebot-Image
Allow: /

User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Allow AI/LLM crawlers for GEO (Generative Engine Optimisation)
User-agent: GPTBot
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: YouBot
Allow: /

User-agent: CCBot
Allow: /
